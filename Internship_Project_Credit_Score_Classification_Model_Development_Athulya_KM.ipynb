{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/athu-lya/Assignment1/blob/main/Internship_Project_Credit_Score_Classification_Model_Development_Athulya_KM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_WgXyp9AhWnZ"
      },
      "outputs": [],
      "source": [
        "#checking Enviornment\n",
        "print('hello world')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SA2vFhpcwWN2"
      },
      "outputs": [],
      "source": [
        "#importing the necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import statistics as stat\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score,confusion_matrix,classification_report"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2C-gD4KVwZLZ"
      },
      "source": [
        "## Build a Classification model with Highest Accuracy, Precison and Recall score. Create a predictive model that categorizes customers into three creditworthiness levels: Good, Standard, and Poor with the given data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KVHqMLfFzOO8"
      },
      "outputs": [],
      "source": [
        "#loading the dataset to the enviornment\n",
        "credit=pd.read_csv('/content/credit (1).csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YPay0rbyzsP8"
      },
      "outputs": [],
      "source": [
        "credit.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jE7a_egK0_Cb"
      },
      "source": [
        "#EDA(Exploratory Data Analysis)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F8gvbwcB1HYl"
      },
      "outputs": [],
      "source": [
        "credit.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zfamp1Ee1aJz"
      },
      "source": [
        "there are 100000 rows and 28 columns in the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LGDOKua41lh-"
      },
      "outputs": [],
      "source": [
        "credit.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8x2KY1fU11Lf"
      },
      "source": [
        "Dataset has 28 features and 100000 entries. Among that, 21 features are numerical (18 float and 3 integer) and 7 are categorical features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WhWPxVv71ziO"
      },
      "outputs": [],
      "source": [
        "credit.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "85wuRZ7E4NCR"
      },
      "outputs": [],
      "source": [
        "credit.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IuDWuQd-4aCb"
      },
      "outputs": [],
      "source": [
        "credit.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4UNGFiyg4kbQ"
      },
      "outputs": [],
      "source": [
        "#check for duplicates\n",
        "credit.duplicated().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KlGABaYr45MP"
      },
      "source": [
        "there is no duplicates in the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c2oH3U6A4_4H"
      },
      "outputs": [],
      "source": [
        "#chech for unique values\n",
        "(credit.nunique()).sort_values(ascending=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PsfgZZXn5ouA"
      },
      "source": [
        "Feature 'ID' and ''Credit_Utilization_Ratio' have full of unique values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oktpn5_jIB3X"
      },
      "outputs": [],
      "source": [
        "credit.drop(['ID','Customer_ID','Month','Name','SSN','Occupation','Type_of_Loan','Credit_Utilization_Ratio'],axis=1,inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qXxN60LbIOfu"
      },
      "source": [
        "droped some unnecessary features by assuming that they donâ€™t have any predictive power to predict the target variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "isHQhbIn6N4E"
      },
      "outputs": [],
      "source": [
        "#check for null values\n",
        "credit.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TLJOWIU47mXQ"
      },
      "source": [
        "There is no null values in the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bAHqxOv2DCcu"
      },
      "outputs": [],
      "source": [
        "#Visualization\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(credit['Age'], kde=True, bins=30)\n",
        "plt.title(\"Histogram of Age\")\n",
        "plt.xlabel(\"Age\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eDyX5EvfDXvj"
      },
      "outputs": [],
      "source": [
        "sns.countplot(x = credit['Credit_Mix'],palette = \"colorblind\");\n",
        "plt.xticks(rotation = 90)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5MKi53Iw_ZlJ"
      },
      "outputs": [],
      "source": [
        "credit[\"Credit_Score\"].value_counts().plot.pie(explode = [0.03,0.03,0.03], autopct=\"%1.2f%%\",shadow = True,labels = [\"Standard\",\"Poor\",\"Good\"])\n",
        "plt.title('Distribution of Credit_Score')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I7yzx5JL_uMx"
      },
      "source": [
        "Data is imbalanced since the majority lies in 'standard' i.e, 53.17%, 29% in 'poor' and less in 'good'(17.83%)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UQXlRqYMFEdY"
      },
      "outputs": [],
      "source": [
        "#Correlation\n",
        "plt.figure(figsize=(16, 8))\n",
        "sns.heatmap(credit.select_dtypes(include=\"number\").corr(),annot=True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7O487bjWFxRu"
      },
      "source": [
        "'Annual_Income' and 'Monthly_Inhand_Salary' have correlation 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T4Z2lqe-uFMD"
      },
      "source": [
        "#**Outlier detection and treatment**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EM4J0uvdIiEu"
      },
      "outputs": [],
      "source": [
        "#check for outliers\n",
        "plt.figure(figsize=(16, 8))\n",
        "sns.boxplot(credit)\n",
        "plt.xticks(rotation=90)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1-LyJFoKDBw"
      },
      "source": [
        "there are outliers present in the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cHgoImfUojVK"
      },
      "outputs": [],
      "source": [
        "new_columns=['Annual_Income','Monthly_Inhand_Salary','Delay_from_due_date', 'Changed_Credit_Limit','Num_Credit_Inquiries', 'Outstanding_Debt', 'Total_EMI_per_month','Amount_invested_monthly', 'Monthly_Balance']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ls6_M15xtTtV"
      },
      "outputs": [],
      "source": [
        "for i in new_columns:\n",
        "    print('Skewness of feature',i,':',credit[i].skew())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m3yU5h1etq5d"
      },
      "source": [
        "All 9 features having outliers are skewed distributions. So using IQR (Inter Quartile Range) method for outlier detection and clip function for outlier treatment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QuXHQlnHo_Mj"
      },
      "outputs": [],
      "source": [
        "for i in new_columns:\n",
        "  plt.figure(i)\n",
        "  plt.boxplot(credit[i])\n",
        "  plt.title(i);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vkRLeRiTMZ4D"
      },
      "outputs": [],
      "source": [
        "for j in ['Annual_Income','Monthly_Inhand_Salary','Delay_from_due_date', 'Changed_Credit_Limit','Num_Credit_Inquiries', 'Outstanding_Debt', 'Total_EMI_per_month','Amount_invested_monthly', 'Monthly_Balance']:\n",
        "    Q1=np.percentile(credit[j],25,method='midpoint')\n",
        "    Q2=np.percentile(credit[j],50,method='midpoint')\n",
        "    Q3=np.percentile(credit[j],75,method='midpoint')\n",
        "    IQR = Q3-Q1\n",
        "    low_lim = Q1-1.5*IQR\n",
        "    up_lim = Q3+1.5*IQR\n",
        "    outliers = []\n",
        "    for h in credit[j]:\n",
        "        if ((h < low_lim) | (h > up_lim)):\n",
        "            outliers.append(h)\n",
        "    credit[j]=credit[j].clip(lower=low_lim,upper=up_lim)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0g2UrxAdoWHg"
      },
      "outputs": [],
      "source": [
        "new_columns1=['Annual_Income','Monthly_Inhand_Salary','Delay_from_due_date', 'Changed_Credit_Limit','Num_Credit_Inquiries', 'Outstanding_Debt', 'Total_EMI_per_month','Amount_invested_monthly', 'Monthly_Balance']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6738KHpwrv_b"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(16, 8))\n",
        "sns.boxplot(credit)\n",
        "plt.xticks(rotation=90)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Mw7-N7ktFO5"
      },
      "source": [
        "All outliers are treated properly. The remaining outliers are the outliers of newly transformed data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gfHtyctFs-iJ"
      },
      "outputs": [],
      "source": [
        "credit.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8wvvdd4nRWwu"
      },
      "outputs": [],
      "source": [
        "#Label encoding\n",
        "le = LabelEncoder()\n",
        "cat_columns=['Credit_Mix','Credit_History_Age','Payment_of_Min_Amount','Credit_Score']\n",
        "for i in cat_columns:\n",
        "    credit[i]=le.fit_transform(credit[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sjMzjetJTy2e"
      },
      "outputs": [],
      "source": [
        "credit.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8NewH4r6UuSZ"
      },
      "outputs": [],
      "source": [
        "#ordinal encoding\n",
        "credit['Payment_Behaviour'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Payment_Behaviour_cat=['Low_spent_Small_value_payments','Low_spent_Medium_value_payments','Low_spent_Large_value_payments',\n",
        "                          'High_spent_Small_value_payments','High_spent_Medium_value_payments','High_spent_Large_value_payments']\n",
        "Payment_Behaviour_encoder=OrdinalEncoder(categories=[Payment_Behaviour_cat])\n",
        "credit['Payment_Behaviour']=Payment_Behaviour_encoder.fit_transform(credit[['Payment_Behaviour']])\n",
        ""
      ],
      "metadata": {
        "id": "mJEHRiDmf4Kl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mefw-OA0TaCf"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(16, 8))\n",
        "sns.heatmap(credit.corr(),annot=True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M2bT6GslVfB4"
      },
      "source": [
        "Since the correlation value of 'Annual_Income' and 'Monthly_Inhand_Salary' are one, they are highly correlated. so that droping 'Monthly_Inhand_Salary'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bzfLgUgSWQcv"
      },
      "outputs": [],
      "source": [
        "credit.drop('Monthly_Inhand_Salary',axis=1,inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3CSsTkHZWnbm"
      },
      "outputs": [],
      "source": [
        "credit.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CUAp6UdbW1vx"
      },
      "outputs": [],
      "source": [
        "#setting the target variable and independentb variables\n",
        "x=credit.drop('Credit_Score',axis=1)\n",
        "y=credit['Credit_Score']\n",
        "y=pd.DataFrame(y,columns=['Credit_Score'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y4b-XllbXRfF"
      },
      "outputs": [],
      "source": [
        "sc=StandardScaler()\n",
        "x_sc=sc.fit_transform(x)\n",
        "x=pd.DataFrame(x_sc,columns=x.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wuePV8DaaiS8"
      },
      "outputs": [],
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
        "x_val, x_test, y_val, y_test = train_test_split(x_test, y_test, test_size=0.5, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z6x_0-wYfmuA"
      },
      "outputs": [],
      "source": [
        "x_train=sc.fit_transform(x_train)\n",
        "x_test=sc.fit_transform(x_test)\n",
        "x_val=sc.fit_transform(x_val)\n",
        "x_test=sc.fit_transform(x_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Cvh1JIM93aY"
      },
      "source": [
        "#Modelling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j--a_cLjANqL"
      },
      "source": [
        "Decision Trees"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oyn2JZ98AvNy"
      },
      "outputs": [],
      "source": [
        "decision_tree = DecisionTreeClassifier()\n",
        "decision_tree.fit(x_train, y_train)\n",
        "decision_tree_pred = decision_tree.predict(x_test)\n",
        "decision_tree_accuracy = accuracy_score(y_test, decision_tree_pred)\n",
        "decision_tree_precision = precision_score(y_test, decision_tree_pred, average='macro')\n",
        "decision_tree_recall = recall_score(y_test, decision_tree_pred, average='macro')\n",
        "decision_tree_f1 = f1_score(y_test, decision_tree_pred, average='macro')\n",
        "print(\"Decision Tree Accuracy:\", decision_tree_accuracy)\n",
        "print(\"confusion_matrix:\", confusion_matrix(y_test,decision_tree_pred))\n",
        "print(\"precision_score:\",decision_tree_precision)\n",
        "print(\"recall_score:\",decision_tree_recall)\n",
        "print(\"f1_score:\",decision_tree_f1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TrOhzBfZCxvZ"
      },
      "source": [
        "Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XFsNPcmUFSce"
      },
      "outputs": [],
      "source": [
        "random_forest = RandomForestClassifier()\n",
        "random_forest.fit(x_train, y_train)\n",
        "random_forest_pred = random_forest.predict(x_test)\n",
        "random_forest_accuracy = accuracy_score(y_test, random_forest_pred)\n",
        "random_forest_precision = precision_score(y_test, random_forest_pred, average='macro')\n",
        "random_forest_recall = recall_score(y_test, random_forest_pred, average='macro')\n",
        "random_forest_f1 = f1_score(y_test, random_forest_pred, average='macro')\n",
        "print(\"Random Forest Accuracy:\", random_forest_accuracy)\n",
        "print(\"confusion_matrix:\", confusion_matrix(y_test,random_forest_pred))\n",
        "print(\"precision_score:\",random_forest_precision)\n",
        "print(\"recall_score:\",random_forest_recall)\n",
        "print(\"f1_score:\",random_forest_f1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uk99_01o_-1J"
      },
      "source": [
        "Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1VnbYax1_kOW"
      },
      "outputs": [],
      "source": [
        "logistic_reg = LogisticRegression()\n",
        "logistic_reg.fit(x_train, y_train)\n",
        "logistic_reg_pred = logistic_reg.predict(x_test)\n",
        "logistic_reg_accuracy = accuracy_score(y_test, logistic_reg_pred)\n",
        "logistic_precision = precision_score(y_test, logistic_reg_pred, average='macro')\n",
        "logistic_recall = recall_score(y_test, logistic_reg_pred, average='macro')\n",
        "logistic_f1 = f1_score(y_test, logistic_reg_pred, average='macro')\n",
        "print(\"logistic_reg_accuracy:\", logistic_reg_accuracy)\n",
        "print(\"confusion_matrix:\", confusion_matrix(y_test,logistic_reg_pred))\n",
        "print(\"precision_score:\",logistic_precision)\n",
        "print(\"recall_score:\",logistic_recall)\n",
        "print(\"f1_score:\",logistic_f1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CQv12mVCBGsE"
      },
      "source": [
        "SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p6Mivp0YKnpS"
      },
      "outputs": [],
      "source": [
        "svm = SVC()\n",
        "svm.fit(x_train, y_train)\n",
        "svm_pred = svm.predict(x_test)\n",
        "svm_accuracy = accuracy_score(y_test, svm_pred)\n",
        "svm_precision = precision_score(y_test, svm_pred, average='macro')\n",
        "svm_recall = recall_score(y_test, svm_pred, average='macro')\n",
        "svm_f1 = f1_score(y_test, svm_pred, average='macro')\n",
        "print(\"SVM Accuracy:\", svm_accuracy)\n",
        "print(\"confusion_matrix:\", confusion_matrix(y_test,svm_pred))\n",
        "print(\"precision_score:\",svm_precision)\n",
        "print(\"recall_score:\",svm_recall)\n",
        "print(\"f1_score:\",svm_f1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1KM76FIuXunh"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "# Define the parameter distribution\n",
        "param_dist = {\n",
        "    'C': [0.01, 0.1, 1, 10, 100],\n",
        "    'penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
        "    'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
        "}\n",
        "\n",
        "# Initialize Random Search\n",
        "random_search = RandomizedSearchCV(estimator=logistic_reg, param_distributions=param_dist, n_iter=100, cv=5, verbose=1, n_jobs=-1, random_state=42)\n",
        "\n",
        "# Fit the model\n",
        "random_search.fit(x_train, y_train)\n",
        "\n",
        "# Get the best parameters and model\n",
        "best_params = random_search.best_params_\n",
        "best_model = random_search.best_estimator_\n",
        "\n",
        "print(\"Best Parameters:\", best_params)\n",
        "print(\"Best Model:\", best_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "acXh5s2DZjfX"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred_lg_hpt = best_model.predict(x_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred_lg_hpt)\n",
        "report = classification_report(y_test, y_pred_lg_hpt)\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Classification Report:\\n\", report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7QVHnipZkdp5"
      },
      "outputs": [],
      "source": [
        "rf_clf1=RandomForestClassifier(n_estimators=10,criterion='entropy',max_features='sqrt') # Changed max_features to 'sqrt'\n",
        "rf_clf1.fit(x_train, y_train)\n",
        "rf_pred1=rf_clf1.predict(x_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jKwzzt3WkuHG"
      },
      "outputs": [],
      "source": [
        "!pip install imbalanced-learn\n",
        "from imblearn.over_sampling import SMOTE\n",
        "# Assuming you have your original training data in x_train and y_train\n",
        "\n",
        "smote = SMOTE(random_state=42)\n",
        "x_train_balanced, y_train_balanced = smote.fit_resample(x_train, y_train)\n",
        "\n",
        "rf_clf1_b=RandomForestClassifier(n_estimators=10,criterion='gini',max_features='sqrt')\n",
        "rf_clf1_b.fit(x_train_balanced, y_train_balanced)\n",
        "rf_pred1_b=rf_clf1_b.predict(x_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FI_-1XXck9fO"
      },
      "outputs": [],
      "source": [
        "dt_clf1=DecisionTreeClassifier(class_weight='balanced',criterion='entropy',max_depth=200)\n",
        "dt_clf1.fit(x_train, y_train)\n",
        "dt_pred1=dt_clf1.predict(x_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wNNswosIk-77"
      },
      "outputs": [],
      "source": [
        "dt_clf1_b=DecisionTreeClassifier(class_weight='balanced',criterion='entropy')\n",
        "dt_clf1_b.fit(x_train_balanced, y_train_balanced)\n",
        "dt_pred1_b=dt_clf1_b.predict(x_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XirWmp4dlIJ0"
      },
      "outputs": [],
      "source": [
        "mux = pd.MultiIndex.from_product([['Without Oversampling','With Oversampling'],['Random Forest','DecisionTree']])\n",
        "Metric=['Train Accuracy','Validation Accuracy','Precision','Recall','F1 Score']\n",
        "comp_table = pd.DataFrame([[rf_clf1.score(x_train,y_train),dt_clf1.score(x_train,y_train),\n",
        "                            rf_clf1_b.score(x_train_balanced,y_train_balanced),dt_clf1_b.score(x_train_balanced,y_train_balanced)],\n",
        "                            [accuracy_score(y_val,rf_pred1),accuracy_score(y_val,dt_pred1),\n",
        "                            accuracy_score(y_val,rf_pred1_b),accuracy_score(y_val,dt_pred1_b)],\n",
        "                            [precision_score(y_val,rf_pred1,average='weighted'),precision_score(y_val,dt_pred1,average='weighted'),\n",
        "                            precision_score(y_val,rf_pred1_b,average='weighted'),precision_score(y_val,dt_pred1_b,average='weighted')],\n",
        "                            [recall_score(y_val,rf_pred1,average='weighted'),recall_score(y_val,dt_pred1,average='weighted'),\n",
        "                            recall_score(y_val,rf_pred1_b,average='weighted'),recall_score(y_val,dt_pred1_b,average='weighted')],\n",
        "                            [f1_score(y_val,rf_pred1,average='weighted'),f1_score(y_val,dt_pred1,average='weighted'),\n",
        "                            f1_score(y_val,rf_pred1_b,average='weighted'),f1_score(y_val,dt_pred1_b,average='weighted')]],columns=mux)\n",
        "comp_table.index=Metric\n",
        "comp_table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4CQ15DrvDD0l"
      },
      "outputs": [],
      "source": [
        "# Import the VotingClassifier\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "voting_clf_hard = VotingClassifier(estimators=[('a1',rf_clf1),('a2',dt_clf1)],voting='hard')\n",
        "voting_clf_hard.fit(x_train, y_train)\n",
        "pred = voting_clf_hard.predict(x_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DDYZ79x--6gu"
      },
      "outputs": [],
      "source": [
        "metric=['Train Accuracy','Validaion Accuracy','Precision','Recall','F1 Score']\n",
        "models=['Random Forest','Decision Tree','Hard Voting Classifier']\n",
        "table= pd.DataFrame([[rf_clf1.score(x_train, y_train),dt_clf1.score(x_train, y_train),voting_clf_hard.score(x_train, y_train)],[accuracy_score(y_val,rf_pred1),accuracy_score(y_val,dt_pred1),accuracy_score(y_val,pred)],[precision_score(y_val,rf_pred1,average='weighted'),precision_score(y_val,dt_pred1,average='weighted'),precision_score(y_val,pred,average='weighted')],[recall_score(y_val,rf_pred1,average='weighted'),recall_score(y_val,dt_pred1,average='weighted'),recall_score(y_val,pred,average='weighted')],[f1_score(y_val,rf_pred1,average='weighted'),f1_score(y_val,dt_pred1,average='weighted'),f1_score(y_val,pred,average='weighted')]],columns=models)\n",
        "table.index=metric\n",
        "table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_QYEKFLW_svz"
      },
      "outputs": [],
      "source": [
        "metric=['Train Accuracy','Test Accuracy','Precision','Recall','F1 Score']\n",
        "table= pd.DataFrame([[dt_clf1.score(x_train,y_train)],[accuracy_score(y_test,test_pred1)],[precision_score(y_test,test_pred1,average='weighted')],[recall_score(y_test,test_pred1,average='weighted')],[f1_score(y_test,test_pred1,average='weighted')]],columns=['Decision Tree'])\n",
        "table.index=metric\n",
        "table"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3y-3h3F3J8US"
      },
      "source": [
        "***Conclusion : Metric values got improved when we do modelling with selected features compared to modelling with full features. So use the selected features only for training and predict test data using the best model obtained - Decision Tree without oversampling.***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XNFmKEHID738"
      },
      "outputs": [],
      "source": [
        "# Assuming you want to use the Decision Tree classifier with balanced class weights\n",
        "test_pred = dt_clf1_b.predict(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3UXxTAmaEKY8"
      },
      "outputs": [],
      "source": [
        "metric=['Train Accuracy','Test Accuracy','Precision','Recall','F1 Score']\n",
        "table= pd.DataFrame([[dt_clf1.score(x_train,y_train)],[accuracy_score(y_test,test_pred)],[precision_score(y_test,test_pred,average='weighted')],[recall_score(y_test,test_pred,average='weighted')],[f1_score(y_test,test_pred,average='weighted')]],columns=['Decision Tree']) #Replaced dt_clf with dt_clf1\n",
        "table.index=metric\n",
        "table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bzM6r5zYEc52"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_dist = { 'max_features': ['auto', 'sqrt', 'log2'], 'max_depth' : [20,50,100], 'criterion' :['gini', 'entropy'] }\n",
        "dtree_reg = DecisionTreeClassifier()\n",
        "grid_search = GridSearchCV(dtree_reg, param_grid=param_dist)\n",
        "grid_search.fit(x_train, y_train)\n",
        "best_params_random = grid_search.best_params_\n",
        "print(f\"Best Parameters for decision tree model: {best_params_random}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nTV4XgL5_rgb"
      },
      "outputs": [],
      "source": [
        "dt_clf1=DecisionTreeClassifier(criterion='gini',max_depth=50,max_features='log2')\n",
        "dt_clf1.fit(x_train,y_train)\n",
        "test_pred1=dt_clf1.predict(x_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kXdDkeoOM8A1"
      },
      "source": [
        "metric values are good"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dl9uty3CFL3t"
      },
      "outputs": [],
      "source": [
        "#cross validation(using stratified k fold cross validation technique)\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "strat_validator=StratifiedKFold(n_splits=10,shuffle=True)\n",
        "cv_result_dt_clf=cross_val_score(dt_clf1,test_pred1.reshape(-1,1),y_test,cv=strat_validator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Spwg87sDAFBn"
      },
      "outputs": [],
      "source": [
        "cv_result_dt_clf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8vFaq-OYAOGh"
      },
      "outputs": [],
      "source": [
        "cv_result_dt_clf.mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wu5ggIQ7Mf3U"
      },
      "source": [
        "Average cross validation score of Decision Tree model is 0.728."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CuTTgh4_AaIe"
      },
      "outputs": [],
      "source": [
        "#confusion matrix\n",
        "cm = confusion_matrix(y_test,test_pred1)\n",
        "sns.heatmap(cm,\n",
        "            annot=True,\n",
        "            fmt='g',\n",
        "            xticklabels=['Good','Poor','Standard'],\n",
        "            yticklabels=['Good','Poor','Standard'])\n",
        "plt.xlabel('Prediction',fontsize=13)\n",
        "plt.ylabel('Actual',fontsize=13)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EXUdjBonAa6P"
      },
      "outputs": [],
      "source": [
        "#classification report\n",
        "print(classification_report(y_test,test_pred1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OWi99qMSQ44x"
      },
      "outputs": [],
      "source": [
        "#saving final model by pickling\n",
        "import pickle\n",
        "with open('model.pkl','wb') as model_file:\n",
        "  pickle.dump(dt_clf1,model_file)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMI98AxA7MbuU8HffErU4XM",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}